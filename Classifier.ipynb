{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed83735d-c81c-458f-bdf2-29ddb8339f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>categorie</th>\n",
       "      <th>wikihow</th>\n",
       "      <th>llama2</th>\n",
       "      <th>llm 0</th>\n",
       "      <th>llm -1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Contact Taco Bell</td>\n",
       "      <td>https://www.wikihow.com/Taco-Bell-Contact</td>\n",
       "      <td>Food and Entertaining</td>\n",
       "      <td>1-800-822-6235This is the number for Taco Bell...</td>\n",
       "      <td>If you have any questions or concerns about ...</td>\n",
       "      <td>To chop onions without tears, there are seve...</td>\n",
       "      <td>Sure, here are some creative ways to use str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don’t Miss Out on These Five Guys Secret Menu ...</td>\n",
       "      <td>https://www.wikihow.com/Five-Guys-Secret-Menu</td>\n",
       "      <td>Food and Entertaining</td>\n",
       "      <td>Your typical burger smothered in extra cheese....</td>\n",
       "      <td>As an expert in food and entertaining, I hig...</td>\n",
       "      <td>Certainly! Green tea is a popular beverage k...</td>\n",
       "      <td>Sure, here are some tips on how to cut sideb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Raise Your Spice Tolerance</td>\n",
       "      <td>https://www.wikihow.com/Adapt-to-Spicy-Food</td>\n",
       "      <td>Food and Entertaining</td>\n",
       "      <td>Start out by adding a dash ofmild hot sauceto ...</td>\n",
       "      <td>Sure, here are some tips on how to raise you...</td>\n",
       "      <td>Sure, here are three quick ways to freeze ba...</td>\n",
       "      <td>Sure, here are some telltale signs that salm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enjoy Vegemite</td>\n",
       "      <td>https://www.wikihow.com/Enjoy-Vegemite</td>\n",
       "      <td>Food and Entertaining</td>\n",
       "      <td>Don't eat it plain.Although it may be common p...</td>\n",
       "      <td>Ah, Vegemite! The quintessential Australian ...</td>\n",
       "      <td>Throwing a surprise party for your mom can b...</td>\n",
       "      <td>Changing a lawn mower blade is a relatively ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eat Marmite</td>\n",
       "      <td>https://www.wikihow.com/Eat-Marmite</td>\n",
       "      <td>Food and Entertaining</td>\n",
       "      <td>Spread Marmiteverysparingly.In Britain and oth...</td>\n",
       "      <td>Marmite is a popular spread made from yeast ...</td>\n",
       "      <td>Sure, here's a brief guide on how to dehydra...</td>\n",
       "      <td>Sure, here is a detailed answer on how to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>Make a Temporary Tattoo with Paper</td>\n",
       "      <td>https://www.wikihow.com/Make-a-Temporary-Tatto...</td>\n",
       "      <td>Personal Care and Style</td>\n",
       "      <td>Purchase water slide paper.Most tattoo sticker...</td>\n",
       "      <td>Creating a temporary tattoo using paper is a...</td>\n",
       "      <td>As an expert in personal care and style, I m...</td>\n",
       "      <td>Determining your neck size and sleeve length...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>Make a Temporary Tattoo Last Longer</td>\n",
       "      <td>https://www.wikihow.com/Make-a-Temporary-Tatto...</td>\n",
       "      <td>Personal Care and Style</td>\n",
       "      <td>Cleanse the spot you plan to tattoo.Lotions, m...</td>\n",
       "      <td>To extend the life of a temporary tattoo bey...</td>\n",
       "      <td>As an expert in personal care and style, I c...</td>\n",
       "      <td>To stay warm during cold winter nights while...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>Create a Sharpie Tattoo</td>\n",
       "      <td>https://www.wikihow.com/Create-a-Sharpie-Tattoo</td>\n",
       "      <td>Personal Care and Style</td>\n",
       "      <td>Draw your tattoo design on your skin.Take your...</td>\n",
       "      <td>Creating a sharpie tattoo is a fun and creat...</td>\n",
       "      <td>Cleaning a cartilage or helix piercing requi...</td>\n",
       "      <td>Painting sheet metal can be a great way to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9398</th>\n",
       "      <td>Draw Your Own Temporary Tattoo</td>\n",
       "      <td>https://www.wikihow.com/Draw-Your-Own-Temporar...</td>\n",
       "      <td>Personal Care and Style</td>\n",
       "      <td>Look for inspiration from other people's tatto...</td>\n",
       "      <td>Creating your own temporary tattoo can be a ...</td>\n",
       "      <td>Creating beaded hair barrettes is a fun and ...</td>\n",
       "      <td>As an expert in personal care and style, I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9399</th>\n",
       "      <td>Get a Tan Tattoo</td>\n",
       "      <td>https://www.wikihow.com/Get-a-Tan-Tattoo</td>\n",
       "      <td>Personal Care and Style</td>\n",
       "      <td>Find a sticker the shape of the tattoo you wan...</td>\n",
       "      <td>A tan tattoo can be a great way to enhance y...</td>\n",
       "      <td>A septum piercing is a form of body modifica...</td>\n",
       "      <td>A frame pegboard is a versatile and space-sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                              How to Contact Taco Bell   \n",
       "1     Don’t Miss Out on These Five Guys Secret Menu ...   \n",
       "2                     How to Raise Your Spice Tolerance   \n",
       "3                                        Enjoy Vegemite   \n",
       "4                                           Eat Marmite   \n",
       "...                                                 ...   \n",
       "9395                 Make a Temporary Tattoo with Paper   \n",
       "9396                Make a Temporary Tattoo Last Longer   \n",
       "9397                            Create a Sharpie Tattoo   \n",
       "9398                     Draw Your Own Temporary Tattoo   \n",
       "9399                                   Get a Tan Tattoo   \n",
       "\n",
       "                                                    url  \\\n",
       "0             https://www.wikihow.com/Taco-Bell-Contact   \n",
       "1         https://www.wikihow.com/Five-Guys-Secret-Menu   \n",
       "2           https://www.wikihow.com/Adapt-to-Spicy-Food   \n",
       "3                https://www.wikihow.com/Enjoy-Vegemite   \n",
       "4                   https://www.wikihow.com/Eat-Marmite   \n",
       "...                                                 ...   \n",
       "9395  https://www.wikihow.com/Make-a-Temporary-Tatto...   \n",
       "9396  https://www.wikihow.com/Make-a-Temporary-Tatto...   \n",
       "9397    https://www.wikihow.com/Create-a-Sharpie-Tattoo   \n",
       "9398  https://www.wikihow.com/Draw-Your-Own-Temporar...   \n",
       "9399           https://www.wikihow.com/Get-a-Tan-Tattoo   \n",
       "\n",
       "                    categorie  \\\n",
       "0       Food and Entertaining   \n",
       "1       Food and Entertaining   \n",
       "2       Food and Entertaining   \n",
       "3       Food and Entertaining   \n",
       "4       Food and Entertaining   \n",
       "...                       ...   \n",
       "9395  Personal Care and Style   \n",
       "9396  Personal Care and Style   \n",
       "9397  Personal Care and Style   \n",
       "9398  Personal Care and Style   \n",
       "9399  Personal Care and Style   \n",
       "\n",
       "                                                wikihow  \\\n",
       "0     1-800-822-6235This is the number for Taco Bell...   \n",
       "1     Your typical burger smothered in extra cheese....   \n",
       "2     Start out by adding a dash ofmild hot sauceto ...   \n",
       "3     Don't eat it plain.Although it may be common p...   \n",
       "4     Spread Marmiteverysparingly.In Britain and oth...   \n",
       "...                                                 ...   \n",
       "9395  Purchase water slide paper.Most tattoo sticker...   \n",
       "9396  Cleanse the spot you plan to tattoo.Lotions, m...   \n",
       "9397  Draw your tattoo design on your skin.Take your...   \n",
       "9398  Look for inspiration from other people's tatto...   \n",
       "9399  Find a sticker the shape of the tattoo you wan...   \n",
       "\n",
       "                                                 llama2  \\\n",
       "0       If you have any questions or concerns about ...   \n",
       "1       As an expert in food and entertaining, I hig...   \n",
       "2       Sure, here are some tips on how to raise you...   \n",
       "3       Ah, Vegemite! The quintessential Australian ...   \n",
       "4       Marmite is a popular spread made from yeast ...   \n",
       "...                                                 ...   \n",
       "9395    Creating a temporary tattoo using paper is a...   \n",
       "9396    To extend the life of a temporary tattoo bey...   \n",
       "9397    Creating a sharpie tattoo is a fun and creat...   \n",
       "9398    Creating your own temporary tattoo can be a ...   \n",
       "9399    A tan tattoo can be a great way to enhance y...   \n",
       "\n",
       "                                                  llm 0  \\\n",
       "0       To chop onions without tears, there are seve...   \n",
       "1       Certainly! Green tea is a popular beverage k...   \n",
       "2       Sure, here are three quick ways to freeze ba...   \n",
       "3       Throwing a surprise party for your mom can b...   \n",
       "4       Sure, here's a brief guide on how to dehydra...   \n",
       "...                                                 ...   \n",
       "9395    As an expert in personal care and style, I m...   \n",
       "9396    As an expert in personal care and style, I c...   \n",
       "9397    Cleaning a cartilage or helix piercing requi...   \n",
       "9398    Creating beaded hair barrettes is a fun and ...   \n",
       "9399    A septum piercing is a form of body modifica...   \n",
       "\n",
       "                                                 llm -1  \n",
       "0       Sure, here are some creative ways to use str...  \n",
       "1       Sure, here are some tips on how to cut sideb...  \n",
       "2       Sure, here are some telltale signs that salm...  \n",
       "3       Changing a lawn mower blade is a relatively ...  \n",
       "4       Sure, here is a detailed answer on how to re...  \n",
       "...                                                 ...  \n",
       "9395    Determining your neck size and sleeve length...  \n",
       "9396    To stay warm during cold winter nights while...  \n",
       "9397    Painting sheet metal can be a great way to a...  \n",
       "9398    As an expert in personal care and style, I c...  \n",
       "9399    A frame pegboard is a versatile and space-sa...  \n",
       "\n",
       "[9400 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Dataset/corpus_CAT.csv\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd4702-f676-4474-a955-74b36345a11b",
   "metadata": {},
   "source": [
    "## Contexte et objectifs du projet MoE\n",
    "\n",
    "L’objectif est de concevoir un système de classification multi-classe basé sur une architecture de type **Mixture of Experts**. Chaque expert est un **modèle binaire** spécialisé pour détecter une seule classe cible, au sein d’un espace commun. L’approche suit une stratégie One-vs-All, où chaque expert est entraîné à reconnaître une catégorie contre toutes les autres.\n",
    "\n",
    "Un **classifieur global** est ainsi construit à partir de plusieurs experts indépendants. Ces derniers sont sélectionnés parmi un ensemble d'algorithmes ou modèles (ex : BERT, RoBERTa, etc.), et leur performance est évaluée via des métriques telles que l’**accuracy**, le **F1-score** et l’**EER** (Equal Error Rate).\n",
    "\n",
    "Un **seuil de décision optimal** peut être défini pour chaque expert en fonction de l’EER. Cela permet d’implémenter un mécanisme de prise de décision.\n",
    "\n",
    "Pour chaque classe :\n",
    "- Les données sont **rééquilibrées** (sous-échantillonnage, sur-échantillonnage) pour corriger le déséquilibre du jeu de données.\n",
    "- Plusieurs modèles peuvent être testés pour une même classe.\n",
    "- L’algorithme retenu est celui qui montre les **meilleures performances** selon la métrique choisie.\n",
    "- Une **permutation dynamique des algorithmes** est envisagée selon les résultats.\n",
    "\n",
    "L’objectif final est de comparer cette approche spécialisée à un classifieur global, et d’identifier les bénéfices en termes de performance, robustesse et contrôle des décisions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea8873a-f8d5-47f1-bdb2-3026551248b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/__init__.py:2222\u001b[0m\n\u001b[1;32m   2218\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, classes)\n\u001b[1;32m   2220\u001b[0m \u001b[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001b[39;00m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[0;32m-> 2222\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/quantization/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_quantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuse_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuse_modules\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuser_method_mappings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/quantization/fake_quantize.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mhere.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_quantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     _is_fake_quant_script_module,\n\u001b[1;32m     12\u001b[0m     _is_per_channel,\n\u001b[1;32m     13\u001b[0m     _is_per_tensor,\n\u001b[1;32m     14\u001b[0m     _is_symmetric_quant,\n\u001b[1;32m     15\u001b[0m     default_fake_quant,\n\u001b[1;32m     16\u001b[0m     default_fixed_qparams_range_0to1_fake_quant,\n\u001b[1;32m     17\u001b[0m     default_fixed_qparams_range_neg1to1_fake_quant,\n\u001b[1;32m     18\u001b[0m     default_fused_act_fake_quant,\n\u001b[1;32m     19\u001b[0m     default_fused_per_channel_wt_fake_quant,\n\u001b[1;32m     20\u001b[0m     default_fused_wt_fake_quant,\n\u001b[1;32m     21\u001b[0m     default_histogram_fake_quant,\n\u001b[1;32m     22\u001b[0m     default_per_channel_weight_fake_quant,\n\u001b[1;32m     23\u001b[0m     default_weight_fake_quant,\n\u001b[1;32m     24\u001b[0m     disable_fake_quant,\n\u001b[1;32m     25\u001b[0m     disable_observer,\n\u001b[1;32m     26\u001b[0m     enable_fake_quant,\n\u001b[1;32m     27\u001b[0m     enable_observer,\n\u001b[1;32m     28\u001b[0m     FakeQuantize,\n\u001b[1;32m     29\u001b[0m     FakeQuantizeBase,\n\u001b[1;32m     30\u001b[0m     FixedQParamsFakeQuantize,\n\u001b[1;32m     31\u001b[0m     FusedMovingAvgObsFakeQuantize,\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuser_method_mappings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpt2e\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_numeric_debugger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     compare_results,\n\u001b[1;32m     14\u001b[0m     CUSTOM_KEY,\n\u001b[1;32m     15\u001b[0m     extract_results_from_loggers,\n\u001b[1;32m     16\u001b[0m     generate_numeric_debug_handle,\n\u001b[1;32m     17\u001b[0m     NUMERIC_DEBUG_HANDLE_KEY,\n\u001b[1;32m     18\u001b[0m     prepare_for_propagation_comparison,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpt2e\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     _allow_exported_model_train_eval \u001b[38;5;28;01mas\u001b[39;00m allow_exported_model_train_eval,\n\u001b[1;32m     22\u001b[0m     _move_exported_model_to_eval \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_eval,\n\u001b[1;32m     23\u001b[0m     _move_exported_model_to_train \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_train,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/pt2e/_numeric_debugger.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mns\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_sqnr\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpt2e\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_control_flow_submodules\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphModule, Node\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/ao/quantization/pt2e/graph_utils.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource_matcher_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     check_subgraphs_connected,\n\u001b[1;32m     10\u001b[0m     get_source_partitions,\n\u001b[1;32m     11\u001b[0m     SourcePartition,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfind_sequential_partitions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_control_flow_submodules\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_equivalent_types\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_equivalent_types_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m ]\n\u001b[1;32m     22\u001b[0m _EQUIVALENT_TYPES: List[Set] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     23\u001b[0m     {torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv1d, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv1d},\n\u001b[1;32m     24\u001b[0m     {torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv2d, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mconv2d},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     {torch\u001b[38;5;241m.\u001b[39mmul, operator\u001b[38;5;241m.\u001b[39mmul, operator\u001b[38;5;241m.\u001b[39mimul, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmul_\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     31\u001b[0m ]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/fx/passes/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     graph_drawer,\n\u001b[1;32m      3\u001b[0m     graph_manipulation,\n\u001b[1;32m      4\u001b[0m     net_min_base,\n\u001b[1;32m      5\u001b[0m     operator_support,\n\u001b[1;32m      6\u001b[0m     param_fetch,\n\u001b[1;32m      7\u001b[0m     reinplace,\n\u001b[1;32m      8\u001b[0m     runtime_assert,\n\u001b[1;32m      9\u001b[0m     shape_prop,\n\u001b[1;32m     10\u001b[0m     split_module,\n\u001b[1;32m     11\u001b[0m     split_utils,\n\u001b[1;32m     12\u001b[0m     splitter_base,\n\u001b[1;32m     13\u001b[0m     tools_common,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/fx/passes/graph_drawer.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _format_arg, _get_qualified_name\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperator_schemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_function\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape_prop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorMetadata\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydot\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/fx/passes/shape_prop.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_python_dispatcher\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect_fake_mode\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_sparse_any\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatibility\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_aggregate, Node\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/_subclasses/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     DynamicOutputShapeException,\n\u001b[1;32m      4\u001b[0m     FakeTensor,\n\u001b[1;32m      5\u001b[0m     FakeTensorMode,\n\u001b[1;32m      6\u001b[0m     UnsupportedFakeTensorException,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossRefFakeMode\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFakeTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFakeTensorMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossRefFakeMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m ]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:68\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fake_tensor_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _CacheKeyState, _PySymInputStub, _SymIntOutputStub\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TracebackType\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/_subclasses/_fake_tensor_utils.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymInt\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msym_node\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymNode\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m py_sym_types, PySymType\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backport_slots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass_slots\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1732\u001b[0m\n\u001b[1;32m   1730\u001b[0m     _make_user_magic(method, SymInt)\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bitwise_ops:\n\u001b[0;32m-> 1732\u001b[0m         _make_user_magic(method, SymFloat)\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m method\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m func\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1538\u001b[0m, in \u001b[0;36m_make_user_magic\u001b[0;34m(method, user_type)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, func \u001b[38;5;129;01min\u001b[39;00m sizes_strides_methods\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1535\u001b[0m     _make_node_sizes_strides(method, func)\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_user_magic\u001b[39m(method, user_type):\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;66;03m# User magic takes care of wrapping the other operand into a node,\u001b[39;00m\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;66;03m# so that our internal logic can assume everything is nodes\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m magic_methods_on_operator_with_trailing_underscore:\n\u001b[1;32m   1543\u001b[0m         method_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msym_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          Trainer, TrainingArguments)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Paramètres du MoE \n",
    "# Ce bloc contient :\n",
    "#    Un dictionnaire 'classes' qui définit quels modèles LLM sont utilisés comme experts\n",
    "#    pour chaque classe du problème de classification.\n",
    "#    Exemple : \"Food and Entertaining\" est pris en charge par 'bert-base-uncased'.\n",
    "#\n",
    "classes = {\n",
    "    \"Food and Entertaining\": \"bert-base-uncased\",\n",
    "    \"Home and Garden\": \"distilbert-base-uncased\",\n",
    "    \"Personal Care and Style\": \"roberta-base\"\n",
    "}\n",
    "\n",
    "#    Dataset pytorch\n",
    "\n",
    "#    Une classe PyTorch personnalisée 'BinaryTextDataset' qui permet de préparer les données\n",
    "#    pour l'entraînement binaire avec un modèle Transformers.\n",
    "#    Elle prend une liste de textes, applique la tokenisation via le tokenizer du modèle,\n",
    "#    et prépare les entrées nécessaires (input_ids, attention_mask, labels) pour le modèle.\n",
    "#    Cette classe est utilisée pour alimenter le Trainer de HuggingFace qu'on utilise.\n",
    "\n",
    "\n",
    "class BinaryTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=64)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n",
    "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n",
    "            \"labels\": torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Boucle d'entraînement des experts.\n",
    "# Pour chaque classe du MoE, on prépare un dataset binaire (la classe en 1, le reste en 0).\n",
    "# Il faut compléter la config du Trainer avec les bons paramètres (epochs, batch, etc),\n",
    "# instancier le Trainer avec le modèle, le dataset et les args,\n",
    "# lancer le fine-tuning, puis sauvegarder le modèle entraîné.\n",
    "# C’est ici qu’on entraîne chaque expert à prendre une décision sur le même espace.\n",
    "\n",
    "# on sauvegarde chaque expert dedans.\n",
    "experts = {}\n",
    "for class_name, model_name in classes.items():\n",
    "    \n",
    "    print(f\"Training expert for class: {class_name}\")\n",
    "\n",
    "    df_temp = df.copy()\n",
    "    df_temp[\"label\"] = (df_temp[\"categorie\"] == class_name).astype(int)\n",
    "\n",
    "    # dataset 9400 ligne on choisit un test_size a 0.2.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_temp[\"title\"], df_temp[\"label\"], test_size=0.2, stratify=df_temp[\"label\"], random_state=42)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    train_dataset = BinaryTextDataset(X_train.tolist(), y_train.tolist(), tokenizer)\n",
    "    eval_dataset = BinaryTextDataset(X_test.tolist(), y_test.tolist(), tokenizer)\n",
    "\n",
    "    # paramètres à réajuster.\n",
    "    # - output_dir : répertoire où les modèles sont stocké.\n",
    "    # - num_train_epochs : le nombre d'epoch.\n",
    "    # - per_device_train_batch_size : taille du batch en entraînement.\n",
    "    # - per_device_eval_batch_size :taille du batch en evaluation.\n",
    "    # - evaluation_strategy : la manière dont on évalue, pour ce cas on fait par epoch.\n",
    "    # - save_strategy : choix de sauvegarde ou non.\n",
    "    # - logging_steps : affichage du log tous les X pas d’entraînement.\n",
    "    # - learning_rate : vitesse d’apprentissage, à adapter par rapport au modele.\n",
    "    # - disable_tqdm : barre de progression à desactiver ou pas.\n",
    "  \n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./moe_{class_name.replace(' ', '_')}\",\n",
    "        num_train_epochs=2,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        disable_tqdm=False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    experts[class_name] = (model.eval(), tokenizer)\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# Fonction d'inférence des modeles\n",
    "# Elle prend un texte en entrée et le fait passer à travers tous les experts disponibles.\n",
    "# Chaque expert donne une probabilité que ce texte appartienne à sa classe.\n",
    "# Ces probabilités sont ensuite pondérées avec un softmax, comme dans l'article du site,\n",
    "# la longueur du texte permet de générer des scores bruts pour le gating.\n",
    "def moe_predict(text):\n",
    "    input_length = len(text)\n",
    "    \n",
    "    weights = F.softmax(torch.tensor(['''TODO on ne reprend pas les meme poids du site, puisque les modèles sont différents''']).float(), dim=0)\n",
    "    probs = []\n",
    "\n",
    "    for i, (class_name, (model, tokenizer)) in enumerate(experts.items()):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\") \n",
    "        # On désactive le calcul des gradients (on ne veut pas entraîner, juste faire une prédiction).\n",
    "        # Ensuite on envoie le texte (déjà tokenisé) dans le modèle, qui nous renvoie un output (0 ou 1 dans notre cas, car classification binaire).\n",
    "        # Le modèle vient de huggingface, et il renvoie par défaut des logit\n",
    "        # Les logits sont des scores brut de \"confiance\" du modèle indiquant si l'input appartient à telle classe ou non.\n",
    "        # Comme dans le site, on les transforme avec un softmax pour obtenir une probabilité.\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "            \n",
    "            # output.logits a la forme [batch_size, num_labels], du coup on prends la premiere ligne du batch\n",
    "            # dans notre cas on a un seul texte, donc a la ligne 0, puis on prend la deuxieme valeur de la ligne \n",
    "            # qui indique si le texte appartient à la classe.\n",
    "            \n",
    "            proba = torch.softmax(output.logits, dim=1)[0, 1]\n",
    "\n",
    "        # ici on multiplie le poid du modele avec la probabilité qu'il nous a retourné, et la fin le but est de ressortir\n",
    "        # dans la liste la classe avec le meilleur score de proba.\n",
    "        \n",
    "        probs.append(proba.item() * weights[i].item())\n",
    "\n",
    "    best_class = list(experts.keys())[torch.tensor(probs).argmax().item()]\n",
    "    return best_class\n",
    "\n",
    "# Utilisation\n",
    "exemple = \"How to cook pasta like a chef\"\n",
    "prediction = moe_predict(exemple)\n",
    "print(f\"Texte : {exemple}\\nClasse prédite : {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22d5f1-c096-4bf3-badd-a5df531a59e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
